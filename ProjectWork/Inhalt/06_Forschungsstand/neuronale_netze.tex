\section{Neuronale Netze} \label{anns}

Ein neuronales Netz bildet die Grundlage des \textit{Deep Learnings}. Neuronale Netze sind komplexe Datenstrukturen, deren kleinste Einheiten aus sogenannten \textit{Linear Threshold Units} (LTUs) bestehen. Diese geben auf Basis von mehreren Eingangswerten einen durch eine Aktivierungsfunktion beschriebenen Ausgangswert aus. Mehrere LTUs sind zusammen in einer eindimensionalen Schicht angeordnet. Ein oder mehrere solcher Schichten bilden ein Perzeptron, den Grundbaustein eines ANNs. Dabei ist jede LTU einer Schicht mit allen LTUs einer folgenden Schicht verbunden. Hier wird auch von sogenannten vollständig verbundenen Schichten (engl.: \textit{Fully-Connected Layer}) gesprochen. Die Verbindungen sind mit einer Gewichtung versehen, die im Lernprozess angepasst werden und somit für bestimmte Eingangsdaten nur bestimmte LTUs aktivieren. Diejenige LTU die am Ende des Netzes alleinig aktiviert ist gibt die Klassifizierung der Eingangsdaten an. Da allerdings meist nicht nur eine LTU alleinig aktiviert ist, findet die Klassifikation auf Basis von Wahrscheinlichkeiten statt. Hierzu wird meist die \textit{Softmax-Funktion}

\begin{equation} \label{softmax}
h_{w}(x) = \sigma(z)_j = \frac{e^{z_j}}{\sum_{i=0}^n e^{z_i} }
\end{equation}
\equations{Die Softmax-Funktion}

verwendet, die den Wert des $j$-ten LTUs einer Schicht mit allen anderen $n$ Werten der LTUs derselben Schicht ins Verhältnis setzt. Falls das neuronale Netz von der Eingangsschicht zur Ausgangsschicht unidirektional von den Eingangsdaten durchlaufen wird, ohne zu bereits besuchten Schichten zurückzukehren, nennt man das neuronale Netz auch \textit{Feed Forward Network}.

Im Wesentlichen existieren vier Methoden, mit deren Hilfe neuronale Netze trainiert werden können: \textit{Überwachten Lernverfahren}, \textit{Halbüberwachte Lernverfahren}, \textit{unüberwachte Lernverfahren} und das \textit{Reinforcement Learning}. Für die Aufgabe der Objektdetektion sind allerdings wesentlich \textit{überwachten Lernverfahren} von Relevanz, die den Trainingsdaten Lösungen, sogenannte \textit{Labels} oder \textit{Annotations}, hinzufügen. Der Lernprozess wird hierbei über das Gradientenverfahren, basierend auf einer Kostenfunktion, und dem Backpropagation Algorithmus ermöglicht. Die Kostenfunktion ist ein Qualitätsmaß dafür, wie weit die Ausgabe einer LTU vom erwarteten Wert abweicht \cite{AurelienGeron.2018}. Eine bekannte Kostenfunktion für das \textit{überwachte Lernen} ist beispielsweise die \textit{Smooth L1} Funktion

\begin{equation} \label{smooth}
SM_{L1}(\boldsymbol{z},\boldsymbol{o}) = \begin{cases}
\sum_{k=0}^n 0.5(z_k-o_k)^2      & \text{wenn } |x| < 1\\
\sum_{k=0}^n |z_k-o_k| - 0.5   & \text{sonst}
\end{cases}
\end{equation}
\equations{Die Smooth L1 Funktion}

, bei der $z$ der erwartete Ausgabevektor des Perzeptrons ist, während $o$ die momentane Ausgabe darstellt.

Für weitere Informationen über das Perzeptron, Lernmethoden, Gradientenverfahren und Backpropagation sind tiefgehendere Kapitel im Anhang hinterlegt.

